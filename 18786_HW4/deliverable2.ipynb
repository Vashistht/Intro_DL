{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(x:List, n:int)->List:\n",
    "    n_gram = []\n",
    "    if len(x) < n:\n",
    "        return None\n",
    "    for i in range(len(x)-n+1):\n",
    "        # print(tuple(x[i:i+n]))\n",
    "        n_gram.append(tuple(x[i:i+n]))\n",
    "    return n_gram\n",
    "\n",
    "# def count_ngram(sentence, ngram):\n",
    "#     # TODO how many times does n-gram g appear in y?\n",
    "#     n_gram_list = create_ngrams(sentence, len(ngram))\n",
    "#     return n_gram_list.count(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(predicted: List[int], target: List[int], N: int) -> float:\n",
    "    \"\"\"\n",
    "    Finds the BLEU-N score between the predicted sentence and a single reference (target) sentence.\n",
    "    Feel free to deviate from this skeleton if you prefer.\n",
    "\n",
    "    Edge case: If the length of the predicted sentence or the target is less than N, return 0.\n",
    "    \"\"\"\n",
    "    if len(predicted) < N or len(target) < N:\n",
    "        return 0  # Edge case\n",
    "    s, s_hat = len(target), len(target)\n",
    "    \n",
    "    \n",
    "    predicted_ngram = create_ngrams(predicted, N)\n",
    "    original_ngram = create_ngrams(target, N)\n",
    "\n",
    "    # unique n-grams in y_hat\n",
    "    unique_predicted_n_gram = list(set(predicted_ngram))\n",
    "    \n",
    "    numerator = 0\n",
    "    geo_mean = 1\n",
    "    for i in range(len(unique_predicted_n_gram)):\n",
    "        g = unique_predicted_n_gram[i]\n",
    "        C_y_hat_g = predicted_ngram.count(g)\n",
    "        C_y_g = original_ngram.count(g)\n",
    "        counter_g = min(C_y_hat_g, C_y_g)\n",
    "        numerator += counter_g # TODO numerator of clipped precision\n",
    "    \n",
    "        denominator =  s_hat- N + 1 # TODO denominator of clipped precision\n",
    "        geo_mean *= (numerator/denominator)**(1/N)\n",
    "    \n",
    "    brevity_penalty = min(1, np.exp(1- (s/s_hat)) ) # TODO\n",
    "    return brevity_penalty * geo_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score_arti(predicted: List[int], target: List[int], N: int) -> float:\n",
    "    \"\"\"\n",
    "    Finds the BLEU-N score between the predicted sentence and a single reference (target) sentence.\n",
    "    Feel free to deviate from this skeleton if you prefer.\n",
    "\n",
    "    Edge case: If the length of the predicted sentence or the target is less than N, return 0.\n",
    "    \"\"\"\n",
    "    if len(predicted) < N or len(target) < N:\n",
    "        return 0\n",
    "    \n",
    "    def C(y, g): # TODO how many times does n-gram g appear in y?\n",
    "        count = 0\n",
    "        for i in range(len(y)-len(g)+1): # for i in number of n-grams           \n",
    "            sub = y[i:i+len(g)]\n",
    "            if sub == list(g):\n",
    "                count += 1\n",
    "        return count\n",
    "        \n",
    "    geo_mean = 1\n",
    "    for n in range(1, N+1):\n",
    "\n",
    "        grams = set() # unique n-grams\n",
    "        for i in range(len(predicted)-n+1): # for i in total number of n-grams\n",
    "            grams.add(tuple(predicted[i:i+n])) # TODO add to grams\n",
    "            \n",
    "        numerator = np.sum(min(C(predicted, g), C(target, g)) for g in grams) # TODO numerator of clipped precision\n",
    "        denominator = len(predicted)-n+1 # TODO denominator of clipped precision\n",
    "        \n",
    "        geo_mean *= (numerator/denominator)**(1/N)\n",
    "    \n",
    "    brevity_penalty = min(1, np.exp(1-len(target)/len(predicted))) # TODO\n",
    "    return brevity_penalty * geo_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/29/2n699yc91qs65qqg0cqgqtlr0000gp/T/ipykernel_6250/2148745900.py:26: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  numerator = np.sum(min(C(predicted, g), C(target, g)) for g in grams) # TODO numerator of clipped precision\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7071067811865476, 0.5976143046671969)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og, pred = [1,2,4,5, 6, 7, 8], [1,3, 4,5,6,7,9]\n",
    "bleu_score(og, pred, 2), bleu_score_arti(og, pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(predicted: List[int], target: List[int], N: int) -> float:\n",
    "    \"\"\"\n",
    "    Finds the BLEU-N score between the predicted sentence and a single reference (target) sentence.\n",
    "    Feel free to deviate from this skeleton if you prefer.\n",
    "\n",
    "    Edge case: If the length of the predicted sentence or the target is less than N, return 0.\n",
    "    \"\"\"\n",
    "    if len(predicted) < N or len(target) < N:\n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    def C(y, g):\n",
    "        # TODO how many times does n-gram g appear in y?\n",
    "        pass\n",
    "\n",
    "    geo_mean = 1\n",
    "    for n in range(1, N+1):\n",
    "        grams = set() # unique n-grams\n",
    "        for i in range(len(predicted)-n+1):\n",
    "            # TODO add to grams\n",
    "            pass\n",
    "        \n",
    "        numerator = None # TODO numerator of clipped precision\n",
    "        denominator = None # TODO denominator of clipped precision\n",
    "\n",
    "        geo_mean *= (numerator/denominator)**(1/N)\n",
    "    \n",
    "    brevity_penalty = None # TODO\n",
    "    return brevity_penalty * geo_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
