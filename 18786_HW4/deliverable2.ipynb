{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(x:List, n:int)->List:\n",
    "    n_gram = []\n",
    "    if len(x) < n:\n",
    "        return None\n",
    "    for i in range(len(x)-n+1):\n",
    "        # print(tuple(x[i:i+n]))\n",
    "        n_gram.append(tuple(x[i:i+n]))\n",
    "    return n_gram\n",
    "\n",
    "# def count_ngram(sentence, ngram):\n",
    "#     # TODO how many times does n-gram g appear in y?\n",
    "#     n_gram_list = create_ngrams(sentence, len(ngram))\n",
    "#     return n_gram_list.count(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_score(predicted: List[int], target: List[int], N: int) -> float:\n",
    "    \"\"\"\n",
    "    Finds the BLEU-N score between the predicted sentence and a single reference (target) sentence.\n",
    "    Feel free to deviate from this skeleton if you prefer.\n",
    "\n",
    "    Edge case: If the length of the predicted sentence or the target is less than N, return 0.\n",
    "    \"\"\"\n",
    "    if len(predicted) < N or len(target) < N:\n",
    "        return 0  # Edge case\n",
    "    \n",
    "    s, s_hat = len(target), len(predicted)\n",
    "    geo_mean = 1\n",
    "    \n",
    "    for n in range(1, N+1):\n",
    "        predicted_ngram = create_ngrams(predicted,n)\n",
    "        original_ngram = create_ngrams(target, n)\n",
    "        \n",
    "        # unique n-grams in y_hat\n",
    "        unique_predicted_n_gram = list(set(predicted_ngram))\n",
    "        counter = 0\n",
    "        for i in range(len(unique_predicted_n_gram)):\n",
    "            g = unique_predicted_n_gram[i]\n",
    "            C_y_hat_g = predicted_ngram.count(g)\n",
    "            C_y_g = original_ngram.count(g)\n",
    "            counter_g = min(C_y_hat_g, C_y_g)\n",
    "            counter += counter_g \n",
    "        \n",
    "        # TODO numerator of clipped precision\n",
    "        numerator = counter\n",
    "        # TODO denominator of clipped precision\n",
    "        denominator =  s_hat- n + 1 \n",
    "        geo_mean *= (numerator/denominator)**(1/N)\n",
    "    # TODO\n",
    "    brevity_penalty = min(1, np.exp(1- (s/s_hat)) )\n",
    "    return brevity_penalty * geo_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
