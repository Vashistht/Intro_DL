{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mytorch.nn.activation import ReLU, Softmax, Tanh, LinearActivation\n",
    "from mytorch.nn.initialization import Xavier, He\n",
    "from mytorch.nn.linear import Linear\n",
    "from mytorch.nn.loss import CrossEntropyLoss, L2Loss\n",
    "from mytorch.optim.optimizer import SGD, Adam\n",
    "from models.mlp import MLP\n",
    "import numpyNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(mlp, x_train, y_train, opt_loss, opt_optim, num_epoch = 20):\n",
    "    \n",
    "    assert(x_train.shape[0]== y_train.shape[1]) # \"x_train and y_train must have same length\"\n",
    "    index = np.arange(len(x_train))\n",
    "    train_loss = []\n",
    "    train_accuracy = [ ]\n",
    "    opt_optim.initialize(mlp.get_parameters() )\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        np.random.shuffle(index)\n",
    "        train_x = x_train[index]\n",
    "        train_y = y_train[index]\n",
    "        \n",
    "        y_pred = mlp.forward(train_x)\n",
    "        \n",
    "        loss = opt_loss.forward(y_pred, train_y)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        predicted_labels = np.argmax(y_pred, axis=1)\n",
    "        true_labels = np.argmax(y_train, axis=1)  # Adjust this line if train_y is not one-hot encoded\n",
    "        accuracy = np.sum(predicted_labels == true_labels) / len(x_train)\n",
    "        print(accuracy)\n",
    "        \n",
    "        dLdZ = opt_loss.backward(y_pred, train_y)\n",
    "        mlp.backward(dLdZ)\n",
    "        opt_optim.step()\n",
    "        opt_optim.zero_grad()\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    train_logs = {\"train_loss\": train_loss, \"train_accuracy\": train_accuracy}\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mlp(mlp, x_test, y_test, opt_loss, num_epoch = 20):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    Returns\n",
    "    -------\n",
    "        [0] Mean test loss.\n",
    "        [1] Test accuracy.\n",
    "    \"\"\"\n",
    "    assert(x_test.shape[0] == y_test.shape[0]) # \"x_test and y_test must have same length\"\n",
    "    \n",
    "    test_loss = []\n",
    "    test_accuracy = [ ]\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        y_pred = mlp.forward(x_test)\n",
    "        # y_label = np.argmax(y_pred, axis=1)\n",
    "        loss = opt_loss.forward(y_pred, y_test)\n",
    "        # y_pred = np.argmax(y_pred, axis=1)\n",
    "        accuracy = np.sum(y_pred == y_test)/len(x_test)\n",
    "        test_loss.append(loss)\n",
    "        test_accuracy.append(accuracy)\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    test_logs = {\"test_loss\": loss, \"test_accuracy\": accuracy}\n",
    "    return test_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on dataset.py from IML HW 6 \n",
    "def one_hot_encoding(y, num_classes=2):\n",
    "    one_hot = np.eye(num_classes)[y.astype(int).flatten()]\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = numpyNN.sample_data(data_name = 'linear-separable',nTrain=2, nTest=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2), (2, 1), (2, 2), (2, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_in, dim_out = x_train.shape[1], 2\n",
    "hidden_neuron_list = [4, 16]\n",
    "activation_list = ['ReLU', 'ReLU', 'Softmax']\n",
    "opt_init = 'xavier'\n",
    "opt_loss = L2Loss()\n",
    "mlp = MLP(dim_in, dim_out, hidden_neuron_list, activation_list, opt_init)\n",
    "opt_optim = SGD(lr_decay=1, decay_iter=30)\n",
    "opt_optim.initialize(mlp.get_parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "-------------\n",
      "Layer 1: Linear - Input Dim: 2, Output Dim: 4, Parameters: 12\n",
      "Layer 2: ReLU\n",
      "Layer 3: Linear - Input Dim: 4, Output Dim: 16, Parameters: 80\n",
      "Layer 4: ReLU\n",
      "Layer 5: Linear - Input Dim: 16, Output Dim: 2, Parameters: 34\n",
      "Layer 6: Softmax\n",
      "Total Parameters: 126\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mlp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': array([[-0.71929844,  0.74017452, -0.05278391,  0.6018215 ],\n",
      "       [ 0.04095496,  0.35775906,  0.44126531,  0.16403958]]), 'grad': None}, {'params': array([[0., 0., 0., 0.]]), 'grad': None}, {'params': array([[ 0.04094032,  0.28329922, -0.43170659, -0.02891929, -0.3436057 ,\n",
      "         0.25953086, -0.31050353, -0.39959847, -0.19264387, -0.38376196,\n",
      "        -0.30418168, -0.12434509,  0.44102453, -0.05482704,  0.12385481,\n",
      "         0.44075079],\n",
      "       [-0.43896638,  0.51465005,  0.1677565 , -0.36050049, -0.15538652,\n",
      "         0.27461291,  0.11812258, -0.19165116, -0.50562961,  0.14708986,\n",
      "         0.50275373,  0.16737341,  0.14794958,  0.54257349,  0.08966254,\n",
      "        -0.09380451],\n",
      "       [-0.0277175 ,  0.13529854, -0.17745377,  0.19143158, -0.20024546,\n",
      "         0.3049122 ,  0.49248041,  0.17803926, -0.53285558,  0.13457116,\n",
      "         0.19023459,  0.51698985,  0.41429019,  0.01054298, -0.48669017,\n",
      "        -0.0535024 ],\n",
      "       [-0.52582717, -0.06385249,  0.52536094, -0.15397088, -0.02093009,\n",
      "         0.20666797,  0.41679045,  0.458154  , -0.31020581,  0.07141083,\n",
      "         0.39994982,  0.009825  ,  0.45649712,  0.46135505, -0.45667738,\n",
      "        -0.24349712]]), 'grad': None}, {'params': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'grad': None}, {'params': array([[-0.56654608,  0.39530258],\n",
      "       [ 0.16994206,  0.39419874],\n",
      "       [-0.27166621, -0.11798643],\n",
      "       [ 0.06099299, -0.38689343],\n",
      "       [-0.15033267, -0.40825389],\n",
      "       [ 0.08038841,  0.23525555],\n",
      "       [-0.24424637, -0.07703231],\n",
      "       [ 0.29572654, -0.11997538],\n",
      "       [ 0.45730574,  0.16041224],\n",
      "       [ 0.45212812,  0.20791026],\n",
      "       [-0.0586614 ,  0.55260611],\n",
      "       [-0.44317186,  0.30833241],\n",
      "       [-0.10182133,  0.2025796 ],\n",
      "       [-0.28891038, -0.21567689],\n",
      "       [ 0.53741636,  0.10215068],\n",
      "       [ 0.1843692 ,  0.03834328]]), 'grad': None}, {'params': array([[0., 0.]]), 'grad': None}]\n"
     ]
    }
   ],
   "source": [
    "print(mlp.get_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = mlp.forward(x_train)\n",
    "y_train = one_hot_encoding(y_train)\n",
    "loss = opt_loss.forward(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.38317163, 0.61682837]]), array([[1., 0.]]), array([0.38047723]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1:4], y_train[1:4], loss[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "true_labels = np.argmax(y_train, axis=1)  # Adjust this line if train_y is not one-hot encoded\n",
    "accuracy = np.sum(predicted_labels == true_labels) / len(x_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward: 0.1967415731239063\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward:\", mlp.layers[0].parameters[0]['params'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61682837,  0.61682837]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdZ = opt_loss.backward(y_pred, y_train)\n",
    "dLdZ[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdZ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': array([[-0.71929844,  0.74017452, -0.05278391,  0.6018215 ],\n",
       "         [ 0.04095496,  0.35775906,  0.44126531,  0.16403958]]),\n",
       "  'grad': None},\n",
       " {'params': array([[0., 0., 0., 0.]]), 'grad': None},\n",
       " {'params': array([[ 0.04094032,  0.28329922, -0.43170659, -0.02891929, -0.3436057 ,\n",
       "           0.25953086, -0.31050353, -0.39959847, -0.19264387, -0.38376196,\n",
       "          -0.30418168, -0.12434509,  0.44102453, -0.05482704,  0.12385481,\n",
       "           0.44075079],\n",
       "         [-0.43896638,  0.51465005,  0.1677565 , -0.36050049, -0.15538652,\n",
       "           0.27461291,  0.11812258, -0.19165116, -0.50562961,  0.14708986,\n",
       "           0.50275373,  0.16737341,  0.14794958,  0.54257349,  0.08966254,\n",
       "          -0.09380451],\n",
       "         [-0.0277175 ,  0.13529854, -0.17745377,  0.19143158, -0.20024546,\n",
       "           0.3049122 ,  0.49248041,  0.17803926, -0.53285558,  0.13457116,\n",
       "           0.19023459,  0.51698985,  0.41429019,  0.01054298, -0.48669017,\n",
       "          -0.0535024 ],\n",
       "         [-0.52582717, -0.06385249,  0.52536094, -0.15397088, -0.02093009,\n",
       "           0.20666797,  0.41679045,  0.458154  , -0.31020581,  0.07141083,\n",
       "           0.39994982,  0.009825  ,  0.45649712,  0.46135505, -0.45667738,\n",
       "          -0.24349712]]),\n",
       "  'grad': None},\n",
       " {'params': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'grad': None},\n",
       " {'params': array([[-0.56654608,  0.39530258],\n",
       "         [ 0.16994206,  0.39419874],\n",
       "         [-0.27166621, -0.11798643],\n",
       "         [ 0.06099299, -0.38689343],\n",
       "         [-0.15033267, -0.40825389],\n",
       "         [ 0.08038841,  0.23525555],\n",
       "         [-0.24424637, -0.07703231],\n",
       "         [ 0.29572654, -0.11997538],\n",
       "         [ 0.45730574,  0.16041224],\n",
       "         [ 0.45212812,  0.20791026],\n",
       "         [-0.0586614 ,  0.55260611],\n",
       "         [-0.44317186,  0.30833241],\n",
       "         [-0.10182133,  0.2025796 ],\n",
       "         [-0.28891038, -0.21567689],\n",
       "         [ 0.53741636,  0.10215068],\n",
       "         [ 0.1843692 ,  0.03834328]]),\n",
       "  'grad': None},\n",
       " {'params': array([[0., 0.]]), 'grad': None}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28921211, 0.96306395],\n",
       "       [1.28921211, 0.96306395]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.backward(dLdZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': array([[-0.71929844,  0.74017452, -0.05278391,  0.6018215 ],\n",
       "         [ 0.04095496,  0.35775906,  0.44126531,  0.16403958]]),\n",
       "  'grad': array([[0.        , 0.78397459, 0.78397459, 0.78397459],\n",
       "         [0.        , 0.05325339, 0.05325339, 0.05325339]])},\n",
       " {'params': array([[0., 0., 0., 0.]]), 'grad': array([[0, 2, 2, 2]])},\n",
       " {'params': array([[ 0.04094032,  0.28329922, -0.43170659, -0.02891929, -0.3436057 ,\n",
       "           0.25953086, -0.31050353, -0.39959847, -0.19264387, -0.38376196,\n",
       "          -0.30418168, -0.12434509,  0.44102453, -0.05482704,  0.12385481,\n",
       "           0.44075079],\n",
       "         [-0.43896638,  0.51465005,  0.1677565 , -0.36050049, -0.15538652,\n",
       "           0.27461291,  0.11812258, -0.19165116, -0.50562961,  0.14708986,\n",
       "           0.50275373,  0.16737341,  0.14794958,  0.54257349,  0.08966254,\n",
       "          -0.09380451],\n",
       "         [-0.0277175 ,  0.13529854, -0.17745377,  0.19143158, -0.20024546,\n",
       "           0.3049122 ,  0.49248041,  0.17803926, -0.53285558,  0.13457116,\n",
       "           0.19023459,  0.51698985,  0.41429019,  0.01054298, -0.48669017,\n",
       "          -0.0535024 ],\n",
       "         [-0.52582717, -0.06385249,  0.52536094, -0.15397088, -0.02093009,\n",
       "           0.20666797,  0.41679045,  0.458154  , -0.31020581,  0.07141083,\n",
       "           0.39994982,  0.009825  ,  0.45649712,  0.46135505, -0.45667738,\n",
       "          -0.24349712]]),\n",
       "  'grad': array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.5993299 , 0.        , 0.5993299 , 0.        , 0.5993299 ,\n",
       "          0.        , 0.5993299 , 0.        , 0.        , 0.        ,\n",
       "          0.5993299 , 0.5993299 , 0.5993299 , 0.5993299 , 0.        ,\n",
       "          0.        ],\n",
       "         [0.09495086, 0.        , 0.09495086, 0.        , 0.09495086,\n",
       "          0.        , 0.09495086, 0.        , 0.        , 0.        ,\n",
       "          0.09495086, 0.09495086, 0.09495086, 0.09495086, 0.        ,\n",
       "          0.        ],\n",
       "         [0.48054843, 0.        , 0.48054843, 0.        , 0.48054843,\n",
       "          0.        , 0.48054843, 0.        , 0.        , 0.        ,\n",
       "          0.48054843, 0.48054843, 0.48054843, 0.48054843, 0.        ,\n",
       "          0.        ]])},\n",
       " {'params': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'grad': array([[2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0]])},\n",
       " {'params': array([[-0.56654608,  0.39530258],\n",
       "         [ 0.16994206,  0.39419874],\n",
       "         [-0.27166621, -0.11798643],\n",
       "         [ 0.06099299, -0.38689343],\n",
       "         [-0.15033267, -0.40825389],\n",
       "         [ 0.08038841,  0.23525555],\n",
       "         [-0.24424637, -0.07703231],\n",
       "         [ 0.29572654, -0.11997538],\n",
       "         [ 0.45730574,  0.16041224],\n",
       "         [ 0.45212812,  0.20791026],\n",
       "         [-0.0586614 ,  0.55260611],\n",
       "         [-0.44317186,  0.30833241],\n",
       "         [-0.10182133,  0.2025796 ],\n",
       "         [-0.28891038, -0.21567689],\n",
       "         [ 0.53741636,  0.10215068],\n",
       "         [ 0.1843692 ,  0.03834328]]),\n",
       "  'grad': array([[ 0.        ,  0.        ],\n",
       "         [-0.27783022,  0.06964557],\n",
       "         [-0.317723  ,  0.08085306],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [-0.27965906,  0.07020796],\n",
       "         [-0.30347941,  0.07620403],\n",
       "         [-0.11551714,  0.02939319],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [-0.12922182,  0.03241965],\n",
       "         [-0.48695313,  0.12277144],\n",
       "         [-0.14904327,  0.03680018],\n",
       "         [-0.3311556 ,  0.08332644],\n",
       "         [-0.52058488,  0.13156037],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]])},\n",
       " {'params': array([[0., 0.]]), 'grad': array([[-1.86496811,  0.4830798 ]])}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before optimization: 0.1967415731239063\n"
     ]
    }
   ],
   "source": [
    "print(\"Before optimization:\", mlp.layers[0].parameters[0]['params'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After optimization: 0.1967415731239063\n"
     ]
    }
   ],
   "source": [
    "print(\"After optimization:\", mlp.layers[0].parameters[0]['params'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': array([[-0.71929844,  0.74017452, -0.05278391,  0.6018215 ],\n",
       "         [ 0.04095496,  0.35775906,  0.44126531,  0.16403958]]),\n",
       "  'grad': array([[0.        , 0.78397459, 0.78397459, 0.78397459],\n",
       "         [0.        , 0.05325339, 0.05325339, 0.05325339]])},\n",
       " {'params': array([[0., 0., 0., 0.]]), 'grad': array([[0, 2, 2, 2]])},\n",
       " {'params': array([[ 0.04094032,  0.28329922, -0.43170659, -0.02891929, -0.3436057 ,\n",
       "           0.25953086, -0.31050353, -0.39959847, -0.19264387, -0.38376196,\n",
       "          -0.30418168, -0.12434509,  0.44102453, -0.05482704,  0.12385481,\n",
       "           0.44075079],\n",
       "         [-0.43896638,  0.51465005,  0.1677565 , -0.36050049, -0.15538652,\n",
       "           0.27461291,  0.11812258, -0.19165116, -0.50562961,  0.14708986,\n",
       "           0.50275373,  0.16737341,  0.14794958,  0.54257349,  0.08966254,\n",
       "          -0.09380451],\n",
       "         [-0.0277175 ,  0.13529854, -0.17745377,  0.19143158, -0.20024546,\n",
       "           0.3049122 ,  0.49248041,  0.17803926, -0.53285558,  0.13457116,\n",
       "           0.19023459,  0.51698985,  0.41429019,  0.01054298, -0.48669017,\n",
       "          -0.0535024 ],\n",
       "         [-0.52582717, -0.06385249,  0.52536094, -0.15397088, -0.02093009,\n",
       "           0.20666797,  0.41679045,  0.458154  , -0.31020581,  0.07141083,\n",
       "           0.39994982,  0.009825  ,  0.45649712,  0.46135505, -0.45667738,\n",
       "          -0.24349712]]),\n",
       "  'grad': array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        ],\n",
       "         [0.5993299 , 0.        , 0.5993299 , 0.        , 0.5993299 ,\n",
       "          0.        , 0.5993299 , 0.        , 0.        , 0.        ,\n",
       "          0.5993299 , 0.5993299 , 0.5993299 , 0.5993299 , 0.        ,\n",
       "          0.        ],\n",
       "         [0.09495086, 0.        , 0.09495086, 0.        , 0.09495086,\n",
       "          0.        , 0.09495086, 0.        , 0.        , 0.        ,\n",
       "          0.09495086, 0.09495086, 0.09495086, 0.09495086, 0.        ,\n",
       "          0.        ],\n",
       "         [0.48054843, 0.        , 0.48054843, 0.        , 0.48054843,\n",
       "          0.        , 0.48054843, 0.        , 0.        , 0.        ,\n",
       "          0.48054843, 0.48054843, 0.48054843, 0.48054843, 0.        ,\n",
       "          0.        ]])},\n",
       " {'params': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       "  'grad': array([[2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0]])},\n",
       " {'params': array([[-0.56654608,  0.39530258],\n",
       "         [ 0.16994206,  0.39419874],\n",
       "         [-0.27166621, -0.11798643],\n",
       "         [ 0.06099299, -0.38689343],\n",
       "         [-0.15033267, -0.40825389],\n",
       "         [ 0.08038841,  0.23525555],\n",
       "         [-0.24424637, -0.07703231],\n",
       "         [ 0.29572654, -0.11997538],\n",
       "         [ 0.45730574,  0.16041224],\n",
       "         [ 0.45212812,  0.20791026],\n",
       "         [-0.0586614 ,  0.55260611],\n",
       "         [-0.44317186,  0.30833241],\n",
       "         [-0.10182133,  0.2025796 ],\n",
       "         [-0.28891038, -0.21567689],\n",
       "         [ 0.53741636,  0.10215068],\n",
       "         [ 0.1843692 ,  0.03834328]]),\n",
       "  'grad': array([[ 0.        ,  0.        ],\n",
       "         [-0.27783022,  0.06964557],\n",
       "         [-0.317723  ,  0.08085306],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [-0.27965906,  0.07020796],\n",
       "         [-0.30347941,  0.07620403],\n",
       "         [-0.11551714,  0.02939319],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [-0.12922182,  0.03241965],\n",
       "         [-0.48695313,  0.12277144],\n",
       "         [-0.14904327,  0.03680018],\n",
       "         [-0.3311556 ,  0.08332644],\n",
       "         [-0.52058488,  0.13156037],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]])},\n",
       " {'params': array([[0., 0.]]), 'grad': array([[-1.86496811,  0.4830798 ]])}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
