{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c574ceac-8715-4368-9f04-1342c814e8fd",
   "metadata": {},
   "source": [
    "# HW1 - Exploring MLPs with PyTorch\n",
    "\n",
    "# Problem 1: Simple MLP for Binary Classification\n",
    "In this problem, you will train a simple MLP to classify two handwritten digits: 0 vs 1. We provide some starter codes to do this task with steps. However, you do not need to follow the exact steps as long as you can complete the task in sections marked as <span style=\"color:red\">[YOUR TASK]</span>.\n",
    "\n",
    "## Dataset Setup\n",
    "We will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The `torchvision` package has supported this dataset. We can load the dataset in this way (the dataset will take up 63M of your disk space):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 - Exploring MLPs with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7de796-0049-4efe-9ea0-ce64a5e24c85",
   "metadata": {},
   "source": [
    "# Problem 3: Handling Class Imbalance in MNIST Dataset\n",
    "In this problem, we will explore how to handle class imbalance problems, which are very common in real-world applications. A modified MNIST dataset is created as follows: we choose all instances of digit “0”, and choose only 1\\% instances of digit “1” for both training and test sets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22857293-024a-4252-a3fb-2cb72cafe0e0",
   "metadata": {},
   "source": [
    "For such a class imbalance problem, accuracy may not be a good metric. Always predicting \"0\" regardless of the input can be 99\\% accurate. Instead, we use the $F_1$ score as the evaluation metric:\n",
    "$$F_1 = 2\\cdot\\frac{\\text{precision}\\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "where precision and recall are defined as:\n",
    "$$\\text{precision}=\\frac{\\text{number of instances correctly predicted as \"1\"}}{\\text{number of instances predicted as \"1\"}}$$\n",
    "$$\\text{recall}=\\frac{\\text{number of instances correctly predicted as \"1\"}}{\\text{number of instances labeled as \"1\"}}$$\n",
    "\n",
    "To handle such a problem, some changes to the training may be necessary. Some suggestions include: \n",
    "1) Adjusting the class weights in the loss function, i.e., use a larger weight for the minority class when computing the loss.\n",
    "2) Implementing resampling techniques (either undersampling the majority class or oversampling the minority class).\n",
    "\n",
    "<span style=\"color:red\">[YOUR TASK]</span>\n",
    "- Create the imbalance datasets with all \"0\" digits and only 1\\% \"1\" digits.\n",
    "- Implement the training loop and evaluation section (implementing the $F_1$ metric). \n",
    "- Ignore the class imbalance problem and train the MLP. Report your hyper-parameter details and the $F_1$ score performance on the test set (as the baseline).\n",
    "- Explore modifications to improve the performance of the class imbalance problem. Report your modifications and the $F_1$ scores performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "872aca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94ec73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2af33ec5-782b-4a0b-819b-f649500627c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data pre-processing\n",
    "# convert the input to the range [-1, 1].\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(0.5, 0.5)]\n",
    "    )\n",
    "\n",
    "# Load the MNIST dataset \n",
    "# this command requires Internet to download the dataset\n",
    "mnist = datasets.MNIST(root='/Users/vashisth/Documents/GitHub/Intro_DL/IDL_hw1/data', \n",
    "                       train=True, \n",
    "                       download=True, \n",
    "                       transform=transform)\n",
    "mnist_test = datasets.MNIST(root='/Users/vashisth/Documents/GitHub/Intro_DL/IDL_hw1/data',   # './data'\n",
    "                            train=False, \n",
    "                            download=True, \n",
    "                            transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a14f718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies:  tensor([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "print(\"Frequencies: \", torch.bincount(mnist.targets))\n",
    "print(len(torch.bincount(mnist.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4c3f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923 6742 12665\n",
      "5923 67 5990\n",
      "980 1135 2115\n",
      "980 11 991\n"
     ]
    }
   ],
   "source": [
    "# Filter for digits 0 and 1\n",
    "import random\n",
    "N= 100\n",
    "train_0 = [data for data in mnist if data[1] == 0]\n",
    "train_1 = [data for data in mnist if data[1] == 1]\n",
    "# random.shuffle(train_1)\n",
    "print(len(train_0), len(train_1), len(train_1) + len( train_0) )\n",
    "train_1 = train_1[:len(train_1) // N]\n",
    "print(len(train_0), len(train_1), len(train_1) + len( train_0) )\n",
    "train_set = train_0 + train_1\n",
    "\n",
    "\n",
    "test_0 = [data for data in mnist_test if data[1] == 0]\n",
    "test_1 = [data for data in mnist_test if data[1] == 1]\n",
    "print(len(test_0), len(test_1), len(test_1) + len( test_0) )\n",
    "\n",
    "test_1 = test_1[:len(test_1) // N]\n",
    "print(len(test_0), len(test_1), len(test_1) + len( test_0) )\n",
    "\n",
    "test_set = test_0 + test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ff472db-51ee-4835-8217-8557947f0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "train_len = int(len(train_set) *.8)\n",
    "val_len = len(train_set) - train_len\n",
    "train_set, val_set = random_split(train_set, [train_len, val_len])\n",
    "\n",
    "# Define DataLoaders to access data in batches\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size = 64, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d6f033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleMLP(\n",
      "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (fc2): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define your MLP\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        # Your code goes here\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Your code goes here\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Your code goes here\n",
    "hidden_dim = 4\n",
    "model = SimpleMLP(in_dim=28 * 28,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  out_dim=2).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "daf6df17-48b9-4617-b12d-1d37865a5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "def precision_score(labels, predictions):\n",
    "    predictions, labels = np.array(labels), np.array(predictions)\n",
    "    predictions_1 = np.sum(predictions==1)\n",
    "    correct_1 = np.sum( (predictions==1) & (labels==1))\n",
    "    precision = correct_1/ predictions_1 if predictions_1 > 0 else 1e-6\n",
    "    return precision\n",
    "\n",
    "def recall_score(labels, predictions):\n",
    "    predictions, labels = np.array(labels), np.array(predictions)\n",
    "    correct_1 = np.sum( (predictions==1) & (labels==1))\n",
    "    labels_1 = np.sum(labels==1)\n",
    "    recall = correct_1/ labels_1 if labels_1 > 0 else 1e-6\n",
    "    return recall\n",
    "\n",
    "def f1_score(labels, predictions):\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = (2 * (recall * precision)) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "09cc3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "05bae893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_digit(weight, batch_size=64):\n",
    "    model = SimpleMLP(in_dim=28 * 28,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  out_dim=2).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight = weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # training\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        correct, count = 0, 0 \n",
    "        for data, target in train_loader:\n",
    "            # free the gradient from the previous batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # reshape the image into a vector\n",
    "            data = data.view(data.size(0), -1)\n",
    "            # model forward\n",
    "            output = model(data)\n",
    "            # compute the loss\n",
    "            loss = criterion(output, target)\n",
    "            # model backward\n",
    "            loss.backward()\n",
    "            # update the model paramters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # adding this for train accuracy \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            count += data.size(0)\n",
    "        \n",
    "        train_acc = 100. * correct / count\n",
    "        # print(f'Training accuracy: {train_acc:.2f}%')\n",
    "\n",
    "    training_time = time.time()- start_time\n",
    "    # print(training_time)\n",
    "    \n",
    "    # validation\n",
    "    val_loss = count = 0\n",
    "    correct = total = 0\n",
    "    val_preds = []; val_labels=[]\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data = data.view(data.size(0), -1)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).item()\n",
    "        count += 1\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += data.size(0)\n",
    "        val_preds.append(pred)\n",
    "        val_labels.append(target)\n",
    "        # print(type(target))\n",
    "\n",
    "    val_preds = torch.cat(val_preds).numpy()\n",
    "    val_labels = torch.cat(val_labels).numpy()\n",
    "    assert len(val_preds) == len(val_set)\n",
    "    \n",
    "    val_loss = val_loss / count\n",
    "    val_acc = 100. * correct / total\n",
    "    # print(f'Validation loss: {val_loss:.2f}, accuracy: {val_acc:.2f}%')\n",
    "    f1_validation = f1_score(labels = val_labels, predictions = val_preds)\n",
    "    # print(f'F1 score validation: {f1_validation:.2f}')\n",
    "    \n",
    "    # test\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    test_preds = []; test_labels=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "            test_preds.append(pred)\n",
    "            test_labels.append(target)\n",
    "        \n",
    "    test_preds = torch.cat(test_preds).numpy()\n",
    "    test_labels = torch.cat(test_labels).numpy()\n",
    "    assert len(test_preds) == len(test_set)   \n",
    "    test_acc = 100. * correct / total\n",
    "    # print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "    # print(f'Validation loss: {val_loss:.2f}, accuracy: {val_acc:.2f}%')\n",
    "    f1_test = f1_score(labels = test_labels, predictions =test_preds)\n",
    "    # print(f'F1 score test: {f1_test:.2f}')\n",
    "    conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    return training_time, train_acc, val_acc, test_acc, f1_validation, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c423d3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0113, 89.4030])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight_0 = len(train_set) / len(train_0)\n",
    "# weight_1 = len(train_set) / len(train_1)\n",
    "# weight_0, weight_1 = weight_0/ (weight_0 + weight_1), weight_1/ (weight_0 + weight_1)\n",
    "total = len(train_0) + len(train_1)\n",
    "weight_0 = total/len(train_0) \n",
    "weight_1 = total/ len(train_1)\n",
    "compensation = torch.tensor([weight_0, weight_1], dtype=torch.float32)\n",
    "compensation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f07f519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[980   0]\n",
      " [ 11   0]]\n",
      "Confusion Matrix:\n",
      "[[980   0]\n",
      " [  0  11]]\n",
      "Confusion Matrix:\n",
      "[[980   0]\n",
      " [  0  11]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Weighing Factor</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Val Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>F1-Val</th>\n",
       "      <th>F1-Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442843</td>\n",
       "      <td>98.789649</td>\n",
       "      <td>99.248748</td>\n",
       "      <td>98.89001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>8.840298</td>\n",
       "      <td>0.464865</td>\n",
       "      <td>99.958264</td>\n",
       "      <td>99.916528</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>88.402977</td>\n",
       "      <td>0.460066</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch size  Weighing Factor  Training Time    Train Acc     Val Acc  \\\n",
       "0          64         1.000000        0.442843   98.789649   99.248748   \n",
       "1          64         8.840298        0.464865   99.958264   99.916528   \n",
       "2          64        88.402977        0.460066  100.000000  100.000000   \n",
       "\n",
       "    Test Acc    F1-Val  F1-Test  \n",
       "0   98.89001  0.000000      0.0  \n",
       "1  100.00000  0.947368      1.0  \n",
       "2  100.00000  1.000000      1.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "results = []\n",
    "weights = [[1,1], [1, (max(compensation)/ min(compensation))/10], compensation]\n",
    "\n",
    "# for batch_size in batch_sizes:\n",
    "for weight in weights:\n",
    "    reweight_factor = max(weight)/ min(weight)\n",
    "    reweight_factor = float(reweight_factor)\n",
    "    weight = torch.tensor([weight_0, weight_1], dtype=torch.float32)\n",
    "    weight = weight.to(device)\n",
    "    training_time, train_acc, val_acc, test_acc, f1_validation, f1_test = two_digit(batch_size=batch_size, weight = weight)\n",
    "    results.append([batch_size,reweight_factor, training_time, train_acc, val_acc, test_acc, f1_validation, f1_test])\n",
    "\n",
    "headers = ['Batch size', 'Weighing Factor', 'Training Time ', 'Train Acc' ,' Val Acc', 'Test Acc', 'F1-Val', 'F1-Test']\n",
    "df =  pd.DataFrame(results, columns = headers)\n",
    "df.to_csv('q3_hyperopt.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd07a3-e41b-4650-b4ae-ed4e2ff6c99d",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">[EXTRA BONUS]</span>\n",
    "\n",
    "If the hyper-parameters are chosen properly, the baseline can perform satisfactorily on the class imbalance problem with 1% digit \"1\". We want to challenge the baseline and handle more class-imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8e4a01-36aa-4fd2-9ec2-cb88db566772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "N = 1000\n",
    "# generate a class-imbalanced dataset controlled by \"N\"\n",
    "train_0 = [data for data in mnist if data[1] == 0]\n",
    "train_1 = [data for data in mnist if data[1] == 1]\n",
    "random.shuffle(train_1)\n",
    "train_1 = train_1[:len(train_1) // N]\n",
    "train_data = train_0 + train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0b82a-def4-45d0-9350-d79f00bfb671",
   "metadata": {},
   "source": [
    "Can you propose new ways for the class imbalance problem and achieve stable and satisfactory performance for large $N = 500, \\; 1000, \\; \\cdots$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47fb7f41-2e28-4935-a9cd-124e4963fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ed5bf-680c-4548-9e47-e5c17316d891",
   "metadata": {},
   "source": [
    "# Problem 4: Reconstruct the MNIST images by Regression\n",
    "In this problem, we want to train the MLP (with only one hidden layer) to complete a regression task: reconstruct the input image. The goal of this task is dimension reduction, and we set the hidden layer dimension to a smaller number, say 50. Once we can train the MLP to reconstruct the input images perfectly, we find an lower dimension representation of the MNIST images.\n",
    "\n",
    "Since this is a reconstruction task, the labels of the images are not needed, and the target is the same as the inputs. Mean Squared Error (MSE) is recommended as the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e5bf64-c614-4ba1-bf3a-2025232a2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c03c6-9b4a-4bc8-86b3-efe72b9db558",
   "metadata": {},
   "source": [
    "Another tip is to add a `torch.nn.Tanh()` activation layer to the end of the model. Recall that our data pre-processing converts the data into the range $[-1, 1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a8cc1aa-cd69-4716-a8a5-ae7ba5a441f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data pre-processing\n",
    "# convert the input to the range [-1, 1].\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(0.5, 0.5)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db3945-7dc5-484b-b6f2-402b0f5a2c1a",
   "metadata": {},
   "source": [
    "Having a `torch.nn.Tanh()` activation layer at the end of the model can convert the output of the model into the range $[-1, 1]$, making the training easier.\n",
    "\n",
    "<span style=\"color:red\">[YOUR TASK]</span>\n",
    "- Define an MLP with only one hidden layer and set the hidden layer dimension as 50. Train the MLP to reconstruct input images from all 10 digits.\n",
    "- Report the Mean Squared Error on the training, validation and test set. Report your hyper-parameter details.\n",
    "- Pick 5 images for each digit from the test set. Visualize the original images and the reconstructed images using the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eb902a8-e07a-421e-80db-12a4d33c1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3a88e-e3b2-4c82-bf42-ab789c452b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
