
\section{Deliverable 4: Classifying CIFAR-10 with ResNet.}


\begin{solve}   
This training was done with first half the samples for 5 epochs, then the best model was saved and then used for training on the entire dataset for 30 epochs. The training logs are as follows:

\begin{lstlisting}[language=python, title=Train Logs, basicstyle=\tiny]
cuda:0
Files already downloaded and verified
Files already downloaded and verified
LOAD DATASET: TRAIN/VAL | 50000/10000
Epoch 1  | Train Loss: 0.7180 | Train Acc: 0.7489 | Val Loss: 0.7228 | Val Acc: 0.7457 | Best Val Loss: 0.7228
Epoch 2  | Train Loss: 0.6359 | Train Acc: 0.7775 | Val Loss: 0.6963 | Val Acc: 0.7637 | Best Val Loss: 0.6963
Epoch 3  | Train Loss: 0.5782 | Train Acc: 0.7987 | Val Loss: 0.7095 | Val Acc: 0.7642 | Best Val Loss: 0.6963
Epoch 4  | Train Loss: 0.5362 | Train Acc: 0.8135 | Val Loss: 0.6472 | Val Acc: 0.7796 | Best Val Loss: 0.6472
Epoch 5  | Train Loss: 0.4877 | Train Acc: 0.8329 | Val Loss: 0.5775 | Val Acc: 0.7978 | Best Val Loss: 0.5775
Epoch 6  | Train Loss: 0.4600 | Train Acc: 0.8404 | Val Loss: 0.6222 | Val Acc: 0.7878 | Best Val Loss: 0.5775
Epoch 7  | Train Loss: 0.4254 | Train Acc: 0.8529 | Val Loss: 0.6284 | Val Acc: 0.7884 | Best Val Loss: 0.5775
Epoch 8  | Train Loss: 0.3964 | Train Acc: 0.8613 | Val Loss: 0.5418 | Val Acc: 0.8159 | Best Val Loss: 0.5418
Epoch 9  | Train Loss: 0.3739 | Train Acc: 0.8709 | Val Loss: 0.5197 | Val Acc: 0.8262 | Best Val Loss: 0.5197
Epoch 10  | Train Loss: 0.3478 | Train Acc: 0.8787 | Val Loss: 0.5211 | Val Acc: 0.8255 | Best Val Loss: 0.5197
Epoch 11  | Train Loss: 0.3267 | Train Acc: 0.8861 | Val Loss: 0.5461 | Val Acc: 0.8205 | Best Val Loss: 0.5197
Epoch 12  | Train Loss: 0.3057 | Train Acc: 0.8925 | Val Loss: 0.4949 | Val Acc: 0.8365 | Best Val Loss: 0.4949
Epoch 13  | Train Loss: 0.2899 | Train Acc: 0.8992 | Val Loss: 0.5026 | Val Acc: 0.8328 | Best Val Loss: 0.4949
Epoch 14  | Train Loss: 0.2696 | Train Acc: 0.9074 | Val Loss: 0.5288 | Val Acc: 0.8284 | Best Val Loss: 0.4949
Epoch 15  | Train Loss: 0.2557 | Train Acc: 0.9098 | Val Loss: 0.5075 | Val Acc: 0.8380 | Best Val Loss: 0.4949
Epoch 16  | Train Loss: 0.2463 | Train Acc: 0.9142 | Val Loss: 0.4827 | Val Acc: 0.8394 | Best Val Loss: 0.4827
Epoch 17  | Train Loss: 0.2274 | Train Acc: 0.9211 | Val Loss: 0.5006 | Val Acc: 0.8459 | Best Val Loss: 0.4827
Epoch 18  | Train Loss: 0.2145 | Train Acc: 0.9260 | Val Loss: 0.4943 | Val Acc: 0.8491 | Best Val Loss: 0.4827
Epoch 19  | Train Loss: 0.2020 | Train Acc: 0.9310 | Val Loss: 0.5065 | Val Acc: 0.8428 | Best Val Loss: 0.4827
Epoch 20  | Train Loss: 0.1964 | Train Acc: 0.9321 | Val Loss: 0.4826 | Val Acc: 0.8500 | Best Val Loss: 0.4826
Epoch 21  | Train Loss: 0.1839 | Train Acc: 0.9349 | Val Loss: 0.5496 | Val Acc: 0.8346 | Best Val Loss: 0.4826
Epoch 22  | Train Loss: 0.1719 | Train Acc: 0.9401 | Val Loss: 0.5164 | Val Acc: 0.8484 | Best Val Loss: 0.4826
Epoch 23  | Train Loss: 0.1675 | Train Acc: 0.9420 | Val Loss: 0.4948 | Val Acc: 0.8536 | Best Val Loss: 0.4826
Epoch 24  | Train Loss: 0.1610 | Train Acc: 0.9438 | Val Loss: 0.4831 | Val Acc: 0.8538 | Best Val Loss: 0.4826
Epoch 25  | Train Loss: 0.1573 | Train Acc: 0.9467 | Val Loss: 0.5056 | Val Acc: 0.8547 | Best Val Loss: 0.4826
Epoch 26  | Train Loss: 0.1460 | Train Acc: 0.9491 | Val Loss: 0.4836 | Val Acc: 0.8596 | Best Val Loss: 0.4826
Epoch 27  | Train Loss: 0.1357 | Train Acc: 0.9523 | Val Loss: 0.5152 | Val Acc: 0.8461 | Best Val Loss: 0.4826
Epoch 28  | Train Loss: 0.1393 | Train Acc: 0.9514 | Val Loss: 0.5040 | Val Acc: 0.8528 | Best Val Loss: 0.4826
Epoch 29  | Train Loss: 0.1306 | Train Acc: 0.9539 | Val Loss: 0.5459 | Val Acc: 0.8490 | Best Val Loss: 0.4826
Epoch 30  | Train Loss: 0.1227 | Train Acc: 0.9587 | Val Loss: 0.4996 | Val Acc: 0.8570 | Best Val Loss: 0.4826
Finished Training
\end{lstlisting}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{/Users/vashisth/Documents/GitHub/Intro_DL/IDL_HW3/HW3_tex/plots/train-loss-curve-del3-4-final.png}
    \caption{Loss Accuracy Plot for Deliverable 4}
\end{figure}

\end{solve}
