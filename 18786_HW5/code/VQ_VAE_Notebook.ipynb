{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Lu_ii31MbQLY"},"outputs":[],"source":["!pip install umap-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODuTi7rklhtj"},"outputs":[],"source":["from __future__ import print_function\n","\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.signal import savgol_filter\n","\n","\n","from six.moves import xrange\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ioJq8eUbQLZ"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"-9In5sLUbQLZ"},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esdbxPadbQLZ"},"outputs":[],"source":["training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,\n","                                  transform=transforms.Compose([\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0))\n","                                  ]))\n","\n","validation_data = datasets.CIFAR10(root=\"data\", train=False, download=True,\n","                                  transform=transforms.Compose([\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0))\n","                                  ]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjLiqJ18bQLa"},"outputs":[],"source":["data_variance = np.var(training_data.data / 255.0)"]},{"cell_type":"markdown","metadata":{"id":"ZE7JB8CsbQLa"},"source":["## Vector Quantizer Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKSgQ2WebQLb"},"outputs":[],"source":["class VectorQuantizer(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n","        super(VectorQuantizer, self).__init__()\n","\n","        self._embedding_dim = embedding_dim\n","        self._num_embeddings = num_embeddings\n","\n","        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n","        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n","        self._commitment_cost = commitment_cost\n","\n","    def forward(self, inputs):\n","        # convert inputs from BCHW -> BHWC\n","        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n","        input_shape = inputs.shape\n","\n","        # Flatten input\n","        flat_input = inputs.view(-1, self._embedding_dim)\n","\n","        # Calculate distances\n","        distances = (torch.sum(flat_input**2, dim=1, keepdim=True)\n","                    + torch.sum(self._embedding.weight**2, dim=1)\n","                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n","\n","        # Encoding\n","        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n","        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n","        encodings.scatter_(1, encoding_indices, 1)\n","\n","        # Quantize and unflatten\n","        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n","\n","        # Loss\n","        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n","        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n","        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n","\n","        quantized = inputs + (quantized - inputs).detach()\n","        avg_probs = torch.mean(encodings, dim=0)\n","        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n","\n","        # convert quantized from BHWC -> BCHW\n","        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings"]},{"cell_type":"markdown","metadata":{"id":"tUcURB0ubQLb"},"source":["## Encoder & Decoder Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGpSGUWbbQLb"},"outputs":[],"source":["class Residual(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n","        super(Residual, self).__init__()\n","        self._block = nn.Sequential(\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=in_channels,\n","                      out_channels=num_residual_hiddens,\n","                      kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=num_residual_hiddens,\n","                      out_channels=num_hiddens,\n","                      kernel_size=1, stride=1, bias=False)\n","        )\n","\n","    def forward(self, x):\n","        return x + self._block(x)\n","\n","\n","class ResidualStack(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(ResidualStack, self).__init__()\n","        self._num_residual_layers = num_residual_layers\n","        self._layers = nn.ModuleList([Residual(in_channels, num_hiddens, num_residual_hiddens)\n","                             for _ in range(self._num_residual_layers)])\n","\n","    def forward(self, x):\n","        for i in range(self._num_residual_layers):\n","            x = self._layers[i](x)\n","        return F.relu(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7itZyE1bQLc"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(Encoder, self).__init__()\n","\n","        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n","                                 out_channels=num_hiddens//2,\n","                                 kernel_size=4,\n","                                 stride=2, padding=1)\n","        self._conv_2 = nn.Conv2d(in_channels=num_hiddens//2,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=4,\n","                                 stride=2, padding=1)\n","        self._conv_3 = nn.Conv2d(in_channels=num_hiddens,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=3,\n","                                 stride=1, padding=1)\n","        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n","                                             num_hiddens=num_hiddens,\n","                                             num_residual_layers=num_residual_layers,\n","                                             num_residual_hiddens=num_residual_hiddens)\n","\n","    def forward(self, inputs):\n","        x = self._conv_1(inputs)\n","        x = F.relu(x)\n","\n","        x = self._conv_2(x)\n","        x = F.relu(x)\n","\n","        x = self._conv_3(x)\n","        return self._residual_stack(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b659HKpRbQLc"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, in_channels, out_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(Decoder, self).__init__()\n","\n","        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=3,\n","                                 stride=1, padding=1)\n","\n","        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n","                                             num_hiddens=num_hiddens,\n","                                             num_residual_layers=num_residual_layers,\n","                                             num_residual_hiddens=num_residual_hiddens)\n","\n","        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens,\n","                                                out_channels=num_hiddens//2,\n","                                                kernel_size=4,\n","                                                stride=2, padding=1)\n","\n","        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2,\n","                                                out_channels=out_channels,\n","                                                kernel_size=4,\n","                                                stride=2, padding=1)\n","\n","    def forward(self, inputs):\n","        x = self._conv_1(inputs)\n","\n","        x = self._residual_stack(x)\n","\n","        x = self._conv_trans_1(x)\n","        x = F.relu(x)\n","\n","        return self._conv_trans_2(x)"]},{"cell_type":"markdown","metadata":{"id":"jIimSGqZbQLc"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GYTRFrBbQLc"},"outputs":[],"source":["batch_size = 256\n","num_training_updates = 5000\n","\n","num_hiddens = 128\n","num_residual_hiddens = 32\n","num_residual_layers = 2\n","\n","embedding_dim = 64\n","num_embeddings = 512\n","\n","commitment_cost = 0.25\n","\n","learning_rate = 1e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_afHsOcbQLc"},"outputs":[],"source":["training_loader = DataLoader(training_data,\n","                             batch_size=batch_size,\n","                             shuffle=True,\n","                             pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPbufjtUbQLd"},"outputs":[],"source":["validation_loader = DataLoader(validation_data,\n","                               batch_size=32,\n","                               shuffle=True,\n","                               pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ufINNhjbQLd"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n","                 num_embeddings, embedding_dim, commitment_cost):\n","        super(Model, self).__init__()\n","\n","        self._encoder = Encoder(3, num_hiddens,\n","                                num_residual_layers,\n","                                num_residual_hiddens)\n","        self._pre_vq_conv = nn.Conv2d(in_channels=num_hiddens,\n","                                      out_channels=embedding_dim,\n","                                      kernel_size=1,\n","                                      stride=1)\n","\n","        self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim,\n","                                           commitment_cost)\n","        self._decoder = Decoder(embedding_dim, 3,\n","                                num_hiddens,\n","                                num_residual_layers,\n","                                num_residual_hiddens)\n","\n","    def forward(self, x):\n","        z = self._encoder(x)\n","        z = self._pre_vq_conv(z)\n","        loss, quantized, perplexity, _ = self._vq_vae(z)\n","        x_recon = self._decoder(quantized)\n","\n","        return loss, x_recon, perplexity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SusDYDHNbQLd"},"outputs":[],"source":["model = Model(num_hiddens, num_residual_layers, num_residual_hiddens,\n","              num_embeddings, embedding_dim,\n","              commitment_cost).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aih3wscibQLd"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j4rA2fnebQLd"},"outputs":[],"source":["model.train()\n","train_res_recon_error = []\n","\n","for i in xrange(num_training_updates):\n","    (data, _) = next(iter(training_loader))\n","    data = data.to(device)\n","    optimizer.zero_grad()\n","\n","    vq_loss, data_recon, perplexity = model(data)\n","    recon_error = F.mse_loss(data_recon, data) / data_variance\n","    loss = recon_error + vq_loss\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    train_res_recon_error.append(recon_error.item())\n","\n","    if (i+1) % 500 == 0:\n","        print('%d iterations' % (i+1))\n","        print('recon_error: %.3f' % np.mean(train_res_recon_error[-100:]))\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"1GsqECDVbQLd"},"source":["## Plot Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zey9c3aNbQLd"},"outputs":[],"source":["train_res_recon_error_smooth = savgol_filter(train_res_recon_error, 201, 7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yeHYsInwbQLd"},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","plt.plot(train_res_recon_error_smooth)\n","plt.yscale('log')\n","plt.title('Smoothed NMSE.')\n","plt.xlabel('iteration')"]},{"cell_type":"markdown","metadata":{"id":"_q8GkAkNbQLd"},"source":["## View Reconstructions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9O4VCCafbQLd"},"outputs":[],"source":["model.eval()\n","\n","(valid_originals, _) = next(iter(validation_loader))\n","valid_originals = valid_originals.to(device)\n","\n","vq_output_eval = model._pre_vq_conv(model._encoder(valid_originals))\n","_, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n","valid_reconstructions = model._decoder(valid_quantize)"]},{"cell_type":"code","source":["torch.max(model._encoder(valid_originals))"],"metadata":{"id":"DX_Wl-tGC3Oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-Ih8lIHbQLd"},"outputs":[],"source":["(train_originals, _) = next(iter(training_loader))\n","train_originals = train_originals.to(device)\n","_, train_reconstructions, _, _ = model._vq_vae(train_originals)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W914Ld-EbQLd"},"outputs":[],"source":["def show(img):\n","    npimg = img.numpy()\n","    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOJaXwsmbQLd"},"outputs":[],"source":["show(make_grid(valid_reconstructions.cpu().data)+0.5, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ENIZHz9bQLe"},"outputs":[],"source":["show(make_grid(valid_originals.cpu()+0.5))"]},{"cell_type":"markdown","metadata":{"id":"1U8NlkOYbQLe"},"source":["## View Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDLuTFShbQLe"},"outputs":[],"source":["import umap.umap_ as umap\n","\n","proj = umap.UMAP(n_neighbors=3,\n","                 min_dist=0.1,\n","                 metric='cosine').fit_transform(model._vq_vae._embedding.weight.data.cpu())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wY7WdEtSbQLe"},"outputs":[],"source":["plt.scatter(proj[:,0], proj[:,1], alpha=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGQ931FYbQLe"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}